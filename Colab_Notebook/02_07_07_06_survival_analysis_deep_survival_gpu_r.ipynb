{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/Survival_Analysis_R/blob/main/Colab_Notebook/02_07_07_06_survival_analysis_deep_survival_gpu_r.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eb7bcf0",
      "metadata": {
        "id": "9eb7bcf0"
      },
      "source": [
        "![All-test](http://drive.google.com/uc?export=view&id=1bLQ3nhDbZrCCqy_WCxxckOne2lgVvn3l)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c788a4d",
      "metadata": {
        "id": "5c788a4d"
      },
      "source": [
        "# 2.7.6 Deep Survival Model - GUP"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20cd9002",
      "metadata": {
        "id": "20cd9002"
      },
      "source": [
        "\n",
        "DeepSurv (Katzman et al., 2018) introduced a breakthrough by replacing the linear predictor of the Cox model with a deep neural network while retaining the same partial likelihood objective. This elegant extension preserves the interpretability of hazard ratios (when needed) and the ability to handle right-censored data, but dramatically increases modeling flexibility.\n",
        "\n",
        "This tutorial demonstrates DeepSurv in R using torch with automatic CUDA (GPU) acceleration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c152c411",
      "metadata": {
        "id": "c152c411"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5781945d",
      "metadata": {
        "id": "5781945d"
      },
      "source": [
        "\n",
        "**DeepSurv** is a deep learning extension of the Cox proportional hazards model. Introduced by Katzman et al. (2018), it replaces the linear predictor in the Cox model with a **fully connected neural network**, enabling the model to capture **nonlinear relationships** and **complex interactions** among covariates while preserving the interpretability of survival risk.\n",
        "\n",
        "Unlike traditional machine learning models that predict point estimates, DeepSurv outputs a **risk score** that is used within the **partial likelihood framework** of Cox regression. This makes it particularly suitable for:\n",
        "\n",
        "- High-dimensional clinical or omics data  \n",
        "- Electronic health records with complex feature interactions  \n",
        "- Scenarios where proportional hazards hold approximately, but linearity does not  \n",
        "\n",
        "This tutorial demonstrates how to implement DeepSurv in **R using the `torch` package**, with and without hyperparameter tuning, using a simulated melanoma dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa0e2162",
      "metadata": {
        "id": "fa0e2162"
      },
      "source": [
        "###  How DeepSurv Works"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8aa4917",
      "metadata": {
        "id": "e8aa4917"
      },
      "source": [
        "\n",
        "\n",
        "The Cox model specifies the hazard for individual $i$ at time $t$ as:\n",
        "\n",
        "$$\n",
        "h_i(t) = h_0(t) \\exp(\\mathbf{x}_i^\\top \\boldsymbol{\\beta})\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $h_0(t)$ is the baseline hazard (nonparametric)  \n",
        "- $\\mathbf{x}_i$ is the vector of covariates  \n",
        "- $\\boldsymbol{\\beta}$ are coefficients  \n",
        "\n",
        "The **partial likelihood** avoids estimating $h_0(t)$ and focuses on ranking events.\n",
        "\n",
        "DeepSurv -  Replacing Linearity with a Neural Network\n",
        "\n",
        "DeepSurv replaces $\\mathbf{x}_i^\\top \\boldsymbol{\\beta}$ with a **neural network risk function** $f_\\theta(\\mathbf{x}_i)$:\n",
        "\n",
        "$$\n",
        "h_i(t) = h_0(t) \\exp(f_\\theta(\\mathbf{x}_i))\n",
        "$$\n",
        "\n",
        "The **negative log partial likelihood** is used as the loss:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\theta) = -\\sum_{i: \\delta_i = 1} \\left[ f_\\theta(\\mathbf{x}_i) - \\log \\left( \\sum_{j \\in \\mathcal{R}(t_i)} \\exp(f_\\theta(\\mathbf{x}_j)) \\right) \\right]\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $\\delta_i = 1$ if event occurred (uncensored)\n",
        "- $\\mathcal{R}(t_i)$ is the risk set at time $t_i$ (all subjects with $t_j \\geq t_i$)\n",
        "\n",
        "In practice, we sort by descending time and compute cumulative sums for efficiency—exactly as implemented in the `cox_nll()` function below.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26a0353a",
      "metadata": {
        "id": "26a0353a"
      },
      "source": [
        "### Why DeepSurv is better than classic Cox in many cases"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1740890",
      "metadata": {
        "id": "c1740890"
      },
      "source": [
        "\n",
        "| Advantage                              | Real-world example                              |\n",
        "|----------------------------------------|--------------------------------------------------|\n",
        "| Captures non-linear effects            | Tumor thickness > 4 mm is much worse than linear assumption |\n",
        "| Learns interactions automatically     | Ulceration + thickness together is far worse than either alone |\n",
        "| Scales to thousands of features        | Works with genomics, radiomics, EHR data        |\n",
        "| Easy to add images, text, time-series  | Multi-modal deep survival models (DeepSurv + CNNs, etc.) |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup R in Python Runtype - Install {rpy2}\n",
        "{rpy2} is a Python package that provides an interface to the R programming language, allowing Python users to run R code, call R functions, and manipulate R objects directly from Python. It enables seamless integration between Python and R, leveraging R's statistical and graphical capabilities while using Python's flexibility. The package supports passing data between the two languages and is widely used for statistical analysis, data visualization, and machine learning tasks that benefit from R's specialized libraries."
      ],
      "metadata": {
        "id": "DwYTV5gk2lCe"
      },
      "id": "DwYTV5gk2lCe"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall rpy2 -y\n",
        "!pip install rpy2==3.5.1\n",
        "%load_ext rpy2.ipython"
      ],
      "metadata": {
        "id": "fXS_vg2h2lMm",
        "outputId": "d962ee5e-c50b-41b9-cb35-d7cf219e3b99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: rpy2 3.5.17\n",
            "Uninstalling rpy2-3.5.17:\n",
            "  Successfully uninstalled rpy2-3.5.17\n",
            "Collecting rpy2==3.5.1\n",
            "  Downloading rpy2-3.5.1.tar.gz (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from rpy2==3.5.1) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from rpy2==3.5.1) (3.1.6)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from rpy2==3.5.1) (2025.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.12/dist-packages (from rpy2==3.5.1) (5.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.23)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->rpy2==3.5.1) (3.0.3)\n",
            "Building wheels for collected packages: rpy2\n",
            "  Building wheel for rpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rpy2: filename=rpy2-3.5.1-cp312-cp312-linux_x86_64.whl size=316569 sha256=89ae16fad1fffae78000c08d45854029920c240c8c9745051d438ffc816d52e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/26/d5/d5e8c0b039915e785be870270e4a9263e5058168a03513d8cc\n",
            "Successfully built rpy2\n",
            "Installing collected packages: rpy2\n",
            "Successfully installed rpy2-3.5.1\n"
          ]
        }
      ],
      "id": "fXS_vg2h2lMm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "POdmPXzWCWVY"
      },
      "id": "POdmPXzWCWVY"
    },
    {
      "cell_type": "code",
      "source": [
        "## Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xDKhBtUC2lkF",
        "outputId": "a260d7d2-b7c3-48c9-ee33-2e7da6dca4be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "xDKhBtUC2lkF"
    },
    {
      "cell_type": "markdown",
      "id": "036306f8",
      "metadata": {
        "id": "036306f8"
      },
      "source": [
        "## DeepSurv in R"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bffcd90",
      "metadata": {
        "id": "7bffcd90"
      },
      "source": [
        "\n",
        "This is a complete working example of DeepSurv on the Melanoma dataset from the MASS package in R, using the torch package for deep learning.\n",
        "\n",
        "Key features of this implementation:\n",
        "\n",
        "- A flexible multi-layer perceptron with ReLU activations and dropout\n",
        "- Exact implementation of the Cox partial negative log-likelihood using pure torch operations\n",
        "- Mini-batch training with Adam optimizer and proper handling of the risk set\n",
        "- Robust indexing to avoid common R/torch pitfalls (e.g., “argument not interpretable as logical”, S3 dispatch errors)\n",
        "- Automatic tracking of training and validation loss\n",
        "- Final evaluation via Harrell’s C-index and visualization of predicted risk stratification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cbcd163",
      "metadata": {
        "id": "1cbcd163"
      },
      "source": [
        "### Install Torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4164a617",
      "metadata": {
        "id": "4164a617"
      },
      "source": [
        "\n",
        "To run this code, you need to have the `torch` package installed. You can install it from CRAN and then install the appropriate LibTorch backend (CPU or CUDA) by running:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c97f883",
      "metadata": {
        "id": "3c97f883"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "install.packages(\"torch\")\n",
        "torch::install_torch()   # will download the right LibTorch (CPU or CUDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ee4c8d",
      "metadata": {
        "id": "28ee4c8d"
      },
      "source": [
        "\n",
        "You can verify that torch is installed correctly by running:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d502ed9",
      "metadata": {
        "id": "7d502ed9"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "library(torch)\n",
        "x <- array(runif(8), dim = c(2, 2, 2))\n",
        "y <- torch_tensor(x, dtype = torch_float64())\n",
        "y\n",
        "identical(x, as_array(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e0d2acb",
      "metadata": {
        "id": "1e0d2acb"
      },
      "source": [
        "### Install Required R Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b073262",
      "metadata": {
        "id": "4b073262"
      },
      "source": [
        "\n",
        "Following R packages are required to run this notebook. If any of these packages are not installed, you can install them using the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30c649b5",
      "metadata": {
        "id": "30c649b5"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "packages <-c(\n",
        "\t\t 'tidyverse',\n",
        "\t\t 'tidyr',\n",
        "\t\t 'Hmisc',\n",
        "\t   'survival',\n",
        "\t\t 'survMisc',\n",
        "\t\t 'survminer',\n",
        "\t\t 'MASS',\n",
        "\t\t 'torch'\n",
        "\n",
        "\t\t )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db858da7",
      "metadata": {
        "id": "db858da7"
      },
      "source": [
        "### Install missing packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Install missing packages\n",
        "new.packages <- packages[!(packages %in% installed.packages(lib='drive/My Drive/R/')[,\"Package\"])]\n",
        "if(length(new.packages)) install.packages(new.packages, lib='drive/My Drive/R/')\n",
        "devtools::install_github(\"ItziarI/WeDiBaDis\", lib='drive/My Drive/R/')\n"
      ],
      "metadata": {
        "id": "Y_TXY0ET2_wy"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Y_TXY0ET2_wy"
    },
    {
      "cell_type": "markdown",
      "id": "1797916e",
      "metadata": {
        "id": "1797916e"
      },
      "source": [
        "### Verify Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c203e93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f1702c-934c-476e-bf95-bde0c22913e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed packages:\n",
            "  tidyverse survivalsvm    survival    survcomp    survMisc   survminer \n",
            "       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE \n",
            "       MASS \n",
            "       TRUE \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Verify installation\n",
        "cat(\"Installed packages:\\n\")\n",
        "print(sapply(packages, requireNamespace, quietly = TRUE))"
      ],
      "id": "8c203e93"
    },
    {
      "cell_type": "markdown",
      "id": "2b351a5d",
      "metadata": {
        "id": "2b351a5d"
      },
      "source": [
        "### Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f1702c-934c-476e-bf95-bde0c22913e6",
        "id": "U8N2suwC62n9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed packages:\n",
            "  tidyverse survivalsvm    survival    survcomp    survMisc   survminer \n",
            "       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE \n",
            "       MASS \n",
            "       TRUE \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Verify installation\n",
        "cat(\"Installed packages:\\n\")\n",
        "print(sapply(packages, requireNamespace, quietly = TRUE))"
      ],
      "id": "U8N2suwC62n9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64654074",
      "metadata": {
        "id": "64654074"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Check loaded packages\n",
        "cat(\"Successfully loaded packages:\\n\")\n",
        "print(search()[grepl(\"package:\", search())])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "469dc306",
      "metadata": {
        "id": "469dc306"
      },
      "source": [
        "###  Simulated Melanoma Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5412b5da",
      "metadata": {
        "id": "5412b5da"
      },
      "source": [
        "\n",
        "We simulate a melanoma dataset (`n = 2000`) with known nonlinear effects (e.g., interaction between tumor thickness and ulceration, sinusoidal terms). The data includes:\n",
        "\n",
        "- `time`: observed survival time  \n",
        "- `event`: binary event indicator (1 = death, 0 = censored)  \n",
        "- Covariates: `age`, `sex`, `thickness`, `ulcer`, `year`\n",
        "\n",
        "This simulation ensures ground-truth performance is measurable (expected C-index ≈ 0.84).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7987aff",
      "metadata": {
        "id": "a7987aff"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "sim_melanoma <- function(n = 2000) {\n",
        "  sex       <- rbinom(n, 1, 0.6)\n",
        "  age       <- rnorm(n, 52, 16) %>% pmax(15) %>% pmin(90)\n",
        "  thickness <- rlnorm(n, 0.5, 1.1)\n",
        "  ulcer     <- rbinom(n, 1, 0.4)\n",
        "  year      <- round(runif(n, 1962, 1977))\n",
        "\n",
        "  lp <- (0.02 * scale(age)[,1] -\n",
        "         0.45 * sex +\n",
        "         0.35 * log1p(thickness) +\n",
        "         0.90 * ulcer -\n",
        "         0.07 * scale(year)[,1] +\n",
        "         0.3 * sin(scale(thickness)[,1] * 2) +\n",
        "         0.5 * ulcer * log1p(thickness))\n",
        "\n",
        "  shape <- 1.3; scale <- 8.0\n",
        "  U <- runif(n)\n",
        "  T_true <- scale * (-log(U) / exp(lp))^(1/shape)\n",
        "  C <- rexp(n, rate = 0.07)\n",
        "  time  <- pmin(T_true, C)\n",
        "  event <- as.numeric(T_true <= C)\n",
        "\n",
        "  data.frame(time, event,\n",
        "             sex = factor(sex, labels = c(\"Male\",\"Female\")),\n",
        "             age, thickness, ulcer = factor(ulcer, labels = c(\"No\",\"Yes\")), year)\n",
        "}\n",
        "\n",
        "df <- sim_melanoma(2000)\n",
        "cat(\"Simulated n =\", nrow(df), \"| Events =\", sum(df$event), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1367b750",
      "metadata": {
        "id": "1367b750"
      },
      "source": [
        "## 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "train_idx <- sample(seq_len(nrow(df)), 1400)\n",
        "val_idx   <- sample(setdiff(seq_len(nrow(df)), train_idx), 300)\n",
        "test_idx  <- setdiff(seq_len(nrow(df)), c(train_idx, val_idx))\n",
        "\n",
        "train_df <- df[train_idx, ]; val_df <- df[val_idx, ]; test_df <- df[test_idx, ]\n",
        "\n",
        "num_cols <- c(\"age\", \"thickness\", \"year\")\n",
        "means <- colMeans(train_df[num_cols])\n",
        "sds   <- apply(train_df[num_cols], 2, sd)\n",
        "\n",
        "scale_df <- function(d) {\n",
        "  d[num_cols] <- scale(d[num_cols], center = means, scale = sds)\n",
        "  d %>% mutate(\n",
        "    sex   = as.numeric(sex)   - 1,\n",
        "    ulcer = as.numeric(ulcer) - 1\n",
        "  )\n",
        "}\n",
        "\n",
        "train_df <- scale_df(train_df)\n",
        "val_df   <- scale_df(val_df)\n",
        "test_df  <- scale_df(test_df)"
      ],
      "metadata": {
        "id": "SFSteZ7L36ym"
      },
      "id": "SFSteZ7L36ym",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert to **GPU-enabled tensors**"
      ],
      "metadata": {
        "id": "fvnHeG1x4Ejl"
      },
      "id": "fvnHeG1x4Ejl"
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# # Detect device (GPU if available, otherwise CPU)\n",
        "device <- if (torch::cuda_is_available()) {\n",
        "  cat(\"GPU detected — using CUDA!\\n\")\n",
        "  torch_device(\"cuda\")\n",
        "} else {\n",
        "  cat(\"No GPU — using CPU\\n\")\n",
        "  torch_device(\"cpu\")\n",
        "}\n",
        "\n",
        "# covert to tensor\n",
        "to_tensor <- function(x) torch_tensor(x, dtype = torch_float(), device = device)\n",
        "\n",
        "x_train <- to_tensor(as.matrix(train_df[, c(\"age\",\"thickness\",\"year\",\"sex\",\"ulcer\")]))\n",
        "x_val   <- to_tensor(as.matrix(val_df[,   c(\"age\",\"thickness\",\"year\",\"sex\",\"ulcer\")]))\n",
        "x_test  <- to_tensor(as.matrix(test_df[,  c(\"age\",\"thickness\",\"year\",\"sex\",\"ulcer\")]))\n",
        "\n",
        "y_time_train  <- to_tensor(train_df$time)\n",
        "y_event_train <- to_tensor(train_df$event)\n",
        "y_time_val    <- to_tensor(val_df$time)\n",
        "y_event_val   <- to_tensor(val_df$event)"
      ],
      "metadata": {
        "id": "uaH6nIYR4E9X"
      },
      "id": "uaH6nIYR4E9X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fed94f3b",
      "metadata": {
        "id": "fed94f3b"
      },
      "source": [
        "## DeepSurv Model and Loss Function (GPU-Compatible)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1348653",
      "metadata": {
        "id": "d1348653"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "make_deepsurv_model <- function(input_dim = 5, hidden1 = 128, hidden2 = 64, hidden3 = 32,\n",
        "                                dropout1 = 0.3, dropout2 = 0.2) {\n",
        "  model <- nn_module(\n",
        "    \"DeepSurv\",\n",
        "    initialize = function(input_dim) {\n",
        "      self$net <- nn_sequential(\n",
        "        nn_linear(input_dim, hidden1), nn_relu(), nn_dropout(dropout1),\n",
        "        nn_linear(hidden1, hidden2),   nn_relu(), nn_dropout(dropout2),\n",
        "        nn_linear(hidden2, hidden3),   nn_relu(),\n",
        "        nn_linear(hidden3, 1)\n",
        "      )\n",
        "    },\n",
        "    forward = function(x) self$net(x)$squeeze(-1)\n",
        "  )(input_dim)\n",
        "\n",
        "  # Move model to device (CPU or CUDA)\n",
        "  model$to(device = device)\n",
        "}\n",
        "\n",
        "cox_nll <- function(risk, time, event) {\n",
        "  ord <- torch_argsort(time, descending = TRUE)\n",
        "  risk <- risk[ord]\n",
        "  event <- event[ord]$bool()\n",
        "  if (event$sum()$item() == 0) return(risk$mean() * 0)\n",
        "\n",
        "  risk <- risk - torch_mean(risk)\n",
        "  risk <- torch_clamp(risk, min = -10, max = 10)\n",
        "\n",
        "  hazard <- torch_exp(-risk)\n",
        "  cum_hazard <- torch_cumsum(hazard, dim = 1L)\n",
        "  cum_hazard <- torch_clamp(cum_hazard, min = 1e-8)\n",
        "  log_cum_hazard <- torch_log(cum_hazard)\n",
        "\n",
        "  uncensored <- torch_nonzero(event)$squeeze()\n",
        "  if (uncensored$dim() == 0) uncensored <- uncensored$unsqueeze(0)\n",
        "\n",
        "  loss <- -(risk[uncensored] - log_cum_hazard[uncensored])$mean()\n",
        "  loss\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27914559",
      "metadata": {
        "id": "27914559"
      },
      "source": [
        "### Case Study 1: Fixed Hyperparameters (with CUDA)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "model <- make_deepsurv_model()\n",
        "optimizer <- optim_adam(model$parameters, lr = 5e-4, weight_decay = 1e-4)\n",
        "\n",
        "epochs <- 500; batch_size <- 128\n",
        "train_losses <- numeric(epochs); val_losses <- numeric(epochs)\n",
        "\n",
        "for (epoch in 1:epochs) {\n",
        "  model$train()\n",
        "  perm <- torch_randperm(x_train$size(1), device = device) + 1L\n",
        "  i <- 1L; batch_loss <- 0; nbat <- 0\n",
        "  while (i <= x_train$size(1)) {\n",
        "    end <- min(i + batch_size - 1, x_train$size(1))\n",
        "    idx <- perm[i:end]\n",
        "\n",
        "    xb <- x_train$index_select(1, idx)\n",
        "    tb <- y_time_train$index_select(1, idx)\n",
        "    eb <- y_event_train$index_select(1, idx)\n",
        "\n",
        "    optimizer$zero_grad()\n",
        "    risk <- model(xb)\n",
        "    loss <- cox_nll(risk, tb, eb)\n",
        "    loss$backward()\n",
        "    optimizer$step()\n",
        "\n",
        "    batch_loss <- batch_loss + loss$item(); nbat <- nbat + 1\n",
        "    i <- i + batch_size\n",
        "  }\n",
        "  train_losses[epoch] <- batch_loss / nbat\n",
        "\n",
        "  if (epoch %% 50 == 0 || epoch == epochs) {\n",
        "    model$eval()\n",
        "    val_loss <- with_no_grad({ cox_nll(model(x_val), y_time_val, y_event_val)$item() })\n",
        "    val_losses[epoch] <- val_loss\n",
        "    cat(sprintf(\"Epoch %3d | Train: %.5f | Val: %.5f\\n\", epoch, train_losses[epoch], val_loss))\n",
        "    model$train()\n",
        "  } else {\n",
        "    val_losses[epoch] <- NA\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "6-wJY0Fb4m4H"
      },
      "id": "6-wJY0Fb4m4H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "27b9e48d",
      "metadata": {
        "id": "27b9e48d"
      },
      "source": [
        "#### Evaluate and visualize results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "model$eval()\n",
        "test_risk_fixed <- as.numeric(with_no_grad({ model(x_test)$cpu() }))\n",
        "cindex_fixed <- Hmisc::rcorr.cens(-test_risk_fixed, Surv(test_df$time, test_df$event))[[\"C Index\"]]\n",
        "cat(\"\\n C-index (Fixed HP):\", round(cindex_fixed, 4), \"\\n\")"
      ],
      "metadata": {
        "id": "IVaHOZl_43UM"
      },
      "id": "IVaHOZl_43UM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f24c831b",
      "metadata": {
        "id": "f24c831b"
      },
      "source": [
        "#### Loss Curve"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "loss_df_fixed <- data.frame(epoch = 1:epochs,\n",
        "                            Training = train_losses,\n",
        "                            Validation = val_losses) %>%\n",
        "  pivot_longer(-epoch, names_to = \"Type\", values_to = \"Loss\")\n",
        "\n",
        "p_loss_fixed <- ggplot(loss_df_fixed, aes(x = epoch, y = Loss, color = Type)) +\n",
        "  geom_line(size = 1.1) +\n",
        "  geom_point(data = subset(loss_df_fixed, Type == \"Validation\" & !is.na(Loss)), size = 3) +\n",
        "  scale_color_manual(values = c(\"Training\" = \"#2E86AB\", \"Validation\" = \"#A23B72\")) +\n",
        "  labs(title = \"DeepSurv (Fixed HP) — Loss Curve\",\n",
        "       subtitle = paste(\"Test C-index =\", round(cindex_fixed, 4)),\n",
        "       x = \"Epoch\", y = \"Cox Negative Log-Likelihood\") +\n",
        "  theme_minimal(base_size = 13) + theme(legend.position = \"top\")\n",
        "p_loss_fixed"
      ],
      "metadata": {
        "id": "3c3wx5kH5EcP"
      },
      "id": "3c3wx5kH5EcP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Kaplan–Meier Plot"
      ],
      "metadata": {
        "id": "_VwXswzQ5Mg7"
      },
      "id": "_VwXswzQ5Mg7"
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# --- KM Plot ---\n",
        "test_df_plot_fixed <- test_df\n",
        "test_df_plot_fixed$risk <- test_risk_fixed\n",
        "test_df_plot_fixed$risk_group <- ifelse(test_risk_fixed >= median(test_risk_fixed), \"High risk\", \"Low risk\")\n",
        "fit_km_fixed <- survfit(Surv(time, event) ~ risk_group, data = test_df_plot_fixed)\n",
        "\n",
        "p_km_fixed <- ggsurvplot(fit_km_fixed, data = test_df_plot_fixed,\n",
        "                         risk.table = TRUE, pval = TRUE,\n",
        "                         palette = c(\"#E41A1C\", \"#377EB8\"),\n",
        "                         legend.labs = c(\"High risk\", \"Low risk\"),\n",
        "                         title = \"DeepSurv Risk Stratification (Fixed HP)\")$plot\n",
        "\n",
        "# Display plots\n",
        "p_km_fixed"
      ],
      "metadata": {
        "id": "02_UprQX5Mvz"
      },
      "id": "02_UprQX5Mvz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3dc9658c",
      "metadata": {
        "id": "3dc9658c"
      },
      "source": [
        "### DeepSurv With Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform **random search** over:\n",
        "- Learning rate: $10^{-5}$ to $10^{-2.5}$\n",
        "- Weight decay: $10^{-6}$ to $10^{-2}$\n",
        "- Architecture sizes and dropout rates\n",
        "\n",
        "Each trial trains for 200 epochs; the best model is retrained for 500 epochs.\n",
        "\n",
        "> ️ **Note**: Each trial model is moved to `device`. Final evaluation moves output to CPU."
      ],
      "metadata": {
        "id": "gK9T4Ytz5fwg"
      },
      "id": "gK9T4Ytz5fwg"
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "best_val_loss <- Inf\n",
        "best_config <- list()\n",
        "\n",
        "for (trial in 1:10) {\n",
        "  lr <- 10^runif(1, -5, -2.5)\n",
        "  wd <- 10^runif(1, -6, -2)\n",
        "  d1 <- runif(1, 0.1, 0.5)\n",
        "  d2 <- runif(1, 0.1, 0.3)\n",
        "  h1 <- sample(c(64,128,256),1); h2 <- sample(c(32,64,128),1); h3 <- sample(c(16,32,64),1)\n",
        "\n",
        "  model_t <- make_deepsurv_model(5, h1, h2, h3, d1, d2)\n",
        "  opt_t <- optim_adam(model_t$parameters, lr = lr, weight_decay = wd)\n",
        "\n",
        "  for (ep in 1:150) {\n",
        "    model_t$train()\n",
        "    perm <- torch_randperm(x_train$size(1), device = device) + 1L\n",
        "    i <- 1L\n",
        "    while (i <= x_train$size(1)) {\n",
        "      end <- min(i + 128 - 1, x_train$size(1))\n",
        "      idx <- perm[i:end]\n",
        "      xb <- x_train$index_select(1, idx)\n",
        "      tb <- y_time_train$index_select(1, idx)\n",
        "      eb <- y_event_train$index_select(1, idx)\n",
        "      opt_t$zero_grad()\n",
        "      risk <- model_t(xb)\n",
        "      loss <- cox_nll(risk, tb, eb)\n",
        "      loss$backward()\n",
        "      opt_t$step()\n",
        "      i <- i + 128\n",
        "    }\n",
        "  }\n",
        "\n",
        "  model_t$eval()\n",
        "  vloss <- with_no_grad({ cox_nll(model_t(x_val), y_time_val, y_event_val)$item() })\n",
        "\n",
        "  if (vloss < best_val_loss) {\n",
        "    best_val_loss <- vloss\n",
        "    best_config <- list(lr=lr, wd=wd, h1=h1, h2=h2, h3=h3, d1=d1, d2=d2, state=model_t$state_dict())\n",
        "  }\n",
        "}\n",
        "\n",
        "# Retrain best model\n",
        "model_tuned <- make_deepsurv_model(5, best_config$h1, best_config$h2, best_config$h3,\n",
        "                                   best_config$d1, best_config$d2)\n",
        "model_tuned$load_state_dict(best_config$state)\n",
        "optimizer_tuned <- optim_adam(model_tuned$parameters, lr = best_config$lr, weight_decay = best_config$wd)\n",
        "\n",
        "# Full training\n",
        "for (epoch in 1:500) {\n",
        "  model_tuned$train()\n",
        "  perm <- torch_randperm(x_train$size(1), device = device) + 1L\n",
        "  i <- 1L\n",
        "  while (i <= x_train$size(1)) {\n",
        "    end <- min(i + 128 - 1, x_train$size(1))\n",
        "    idx <- perm[i:end]\n",
        "    xb <- x_train$index_select(1, idx)\n",
        "    tb <- y_time_train$index_select(1, idx)\n",
        "    eb <- y_event_train$index_select(1, idx)\n",
        "    optimizer_tuned$zero_grad()\n",
        "    risk <- model_tuned(xb)\n",
        "    loss <- cox_nll(risk, tb, eb)\n",
        "    loss$backward()\n",
        "    optimizer_tuned$step()\n",
        "    i <- i + 128\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "tzBMPLes5sKx"
      },
      "id": "tzBMPLes5sKx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate and visualize results"
      ],
      "metadata": {
        "id": "mhvGgRZV54UW"
      },
      "id": "mhvGgRZV54UW"
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "model_tuned$eval()\n",
        "test_risk_tuned <- as.numeric(with_no_grad({ model_tuned(x_test)$cpu() }))\n",
        "cindex_tuned <- Hmisc::rcorr.cens(-test_risk_tuned, Surv(test_df$time, test_df$event))[[\"C Index\"]]\n",
        "cat(\"\\n C-index (Tuned HP):\", round(cindex_tuned, 4), \"\\n\")"
      ],
      "metadata": {
        "id": "sYvQ-6jH55Cf"
      },
      "id": "sYvQ-6jH55Cf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss Curve"
      ],
      "metadata": {
        "id": "abOzkpX05_xv"
      },
      "id": "abOzkpX05_xv"
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# --- Loss Plot ---\n",
        "loss_df_tuned <- data.frame(epoch = 1:500,\n",
        "                            Training = train_losses_tuned,\n",
        "                            Validation = val_losses_tuned) %>%\n",
        "  pivot_longer(-epoch, names_to = \"Type\", values_to = \"Loss\")\n",
        "\n",
        "p_loss_tuned <- ggplot(loss_df_tuned, aes(x = epoch, y = Loss, color = Type)) +\n",
        "  geom_line(size = 1.1) +\n",
        "  geom_point(data = subset(loss_df_tuned, Type == \"Validation\" & !is.na(Loss)), size = 3) +\n",
        "  scale_color_manual(values = c(\"Training\" = \"#2E86AB\", \"Validation\" = \"#A23B72\")) +\n",
        "  labs(title = \"DeepSurv (Tuned HP) — Loss Curve\",\n",
        "       subtitle = paste(\"Test C-index =\", round(cindex_tuned, 4)),\n",
        "       x = \"Epoch\", y = \"Cox Negative Log-Likelihood\") +\n",
        "  theme_minimal(base_size = 13) + theme(legend.position = \"top\")\n",
        "p_loss_tuned"
      ],
      "metadata": {
        "id": "czlOyAn06FOr"
      },
      "id": "czlOyAn06FOr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Kaplan–Meier Plot"
      ],
      "metadata": {
        "id": "sB3wN08w6Jf3"
      },
      "id": "sB3wN08w6Jf3"
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# --- KM Plot ---\n",
        "test_df_plot_tuned <- test_df\n",
        "test_df_plot_tuned$risk <- test_risk_tuned\n",
        "test_df_plot_tuned$risk_group <- ifelse(test_risk_tuned >= median(test_risk_tuned), \"High risk\", \"Low risk\")\n",
        "fit_km_tuned <- survfit(Surv(time, event) ~ risk_group, data = test_df_plot_tuned)\n",
        "\n",
        "p_km_tuned <- ggsurvplot(fit_km_tuned, data = test_df_plot_tuned,\n",
        "                         risk.table = TRUE, pval = TRUE,\n",
        "                         palette = c(\"#E41A1C\", \"#377EB8\"),\n",
        "                         legend.labs = c(\"High risk\", \"Low risk\"),\n",
        "                         title = \"DeepSurv Risk Stratification (Tuned HP)\")$plot\n",
        "\n",
        "# Display plots\n",
        "p_km_tuned"
      ],
      "metadata": {
        "id": "lzdf3mxp6Juu"
      },
      "id": "lzdf3mxp6Juu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Resources\n",
        "\n",
        "- **Original Paper**: Katzman et al. (2018). [DeepSurv](https://doi.org/10.1186/s12874-018-0482-1)  \n",
        "- **R `torch`**: https://torch.mlverse.org/  \n",
        "- **Survival Analysis in R**: *Therneau & Grambsch (2000). Modeling Survival Data*  \n",
        "- **Code Repository**: [github.com/jaredleekatzman/DeepSurv](https://github.com/jaredleekatzman/DeepSurv) (Python)  \n",
        "- **Alternative R Packages**: `survival`, `rms`, `mlr3proba`, `torchopt`"
      ],
      "metadata": {
        "id": "Y0CUFJzz6WtN"
      },
      "id": "Y0CUFJzz6WtN"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}